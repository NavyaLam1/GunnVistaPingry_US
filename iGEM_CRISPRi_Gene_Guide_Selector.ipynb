{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialization\n",
    "    * Initialize variables\n",
    "    * Load Scripts\n",
    "2. Applying machine learning model to predict sgRNA activity\n",
    "    * Find all sgRNAs in genomic regions of interest \n",
    "    * Predicting sgRNA activity\n",
    "3. Construct sgRNA libraries\n",
    "    * Score sgRNAs for off-target potential\n",
    "* Pick the top sgRNAs for a library, given predicted activity scores and off-target filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization\n",
    "## Initialize variables and load scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Modif this variable to add genes for which you want to find guideRNAs\n",
    "GENES_LIST_TO_FIND_GUIDES = ['APOL1','APOL3','PRRC2A']\n",
    "\n",
    "#modify below variable to point to the base directory containing large genome data files\n",
    "#LARGE_FILE_DIR= '../../../../data/'\n",
    "LARGE_FILE_DIR= './'\n",
    "\n",
    "\n",
    "FASTA_FILE_OF_GENOME= LARGE_FILE_DIR + 'large_data_files/hg19.fa'\n",
    "GTF_FILE_FROM_GENCODE = LARGE_FILE_DIR + 'large_data_files/gencode.v19.annotation.gtf'\n",
    "\n",
    "TSS_TABLE_PATH='data_files/human_tssTable.txt'\n",
    "P1P2_TABLE_PATH='data_files/human_p1p2Table.txt'\n",
    "\n",
    "FANTOM_TSS_ANNOTATION_BED= LARGE_FILE_DIR + 'large_data_files/TSS_human.sorted.bed.gz'\n",
    "HGNC_SYMBOL_LOOKUP_TABLE= LARGE_FILE_DIR + 'large_data_files/hgnc_complete_set_2020-08-01.txt'\n",
    "\n",
    "#spreadsheet containing the lab experiment data to train the model\n",
    "IGEM_EXCEL_FILE= 'data_files/Sam_Perli_qRT_pcr_data_per_gene.xlsx'\n",
    "\n",
    "\n",
    "PICKLE_FILE = 'igem_v1_estimator'\n",
    "TRANSFORMED_PARAM_HEADER='igem_v1_transformed_param_header'\n",
    "\n",
    "PREDICTED_SCORE_TABLE='igem_v1_predicted_score_table'\n",
    "TEMP_FASTQ_FILE='igem_v1_temp_fastq_file'\n",
    "\n",
    "\n",
    "%run sgRNA_learning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Applying machine learning model to predict sgRNA activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we load our trained model\n",
    "import _pickle as cPickle\n",
    "\n",
    "#load tssTable, p1p2Table, genome sequence, chromatin data\n",
    "tssTable = pd.read_csv(TSS_TABLE_PATH,sep='\\t', index_col=[0,1])\n",
    "\n",
    "p1p2Table = pd.read_csv(P1P2_TABLE_PATH,sep='\\t', header=0, index_col=[0,1])\n",
    "p1p2Table['primary TSS'] = p1p2Table['primary TSS'].apply(lambda tupString: (int(float(tupString.strip('()').split(', ')[0])), int(float(tupString.strip('()').split(', ')[1]))))\n",
    "p1p2Table['secondary TSS'] = p1p2Table['secondary TSS'].apply(lambda tupString: (int(float(tupString.strip('()').split(', ')[0])),int(float(tupString.strip('()').split(', ')[1]))))\n",
    "\n",
    "genomeDict = loadGenomeAsDict(FASTA_FILE_OF_GENOME)\n",
    "\n",
    "bwhandleDict = {'dnase':BigWigFile(open(LARGE_FILE_DIR + 'large_data_files/wgEncodeOpenChromDnaseK562BaseOverlapSignalV2.bigWig','rb')),\n",
    "'faire':BigWigFile(open(LARGE_FILE_DIR + 'large_data_files/wgEncodeOpenChromFaireK562Sig.bigWig','rb')),\n",
    "'mnase':BigWigFile(open(LARGE_FILE_DIR + 'large_data_files/wgEncodeSydhNsomeK562Sig.bigWig','rb'))}\n",
    "\n",
    "#load sgRNA prediction model saved after the parameter fitting step\n",
    "with open(PICKLE_FILE,'rb') as infile:\n",
    "    fitTable, estimators, scaler, reg, (geneFold_train, geneFold_test) = cPickle.load(infile)\n",
    "    \n",
    "#transformedParamHeader = pd.read_csv(TRANSFORMED_PARAM_HEADER,sep='\\t')\n",
    "\n",
    "#iGEM read the binary file\n",
    "#transformedParamHeader = pd.read_csv(TRANSFORMED_PARAM_HEADER,sep='\\t')\n",
    "\n",
    "with open(TRANSFORMED_PARAM_HEADER,'rb') as paraminfile:\n",
    "    transformedParamHeader = cPickle.load(paraminfile)\n",
    "\n",
    "transformedParams_train = transformedParamHeader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all sgRNAs in genomic regions of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create gene and sgRna table\n",
    "libraryTable_new, sgInfoTable_new = findAllGuides(p1p2Table, genomeDict, (-25,500))\n",
    "\n",
    "#Filter the genes  that we are interested in\n",
    "libraryTable_new = libraryTable_new[ (libraryTable_new['gene'].isin(GENES_LIST_TO_FIND_GUIDES))]\n",
    "sgInfoTable_new = parseAllSgIds(libraryTable_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryTable_new.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting sgRNA activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate parameters for new sgRNAs\n",
    "paramTable_new = generateTypicalParamTableEx(libraryTable_new, sgInfoTable_new, tssTable, p1p2Table, genomeDict, bwhandleDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform and predict scores according to sgRNA prediction model\n",
    "transformedParams_new = transformParams(paramTable_new, fitTable, estimators)\n",
    "\n",
    "#reconcile any differences in column headers generated by automated binning\n",
    "colTups = []\n",
    "for (l1, l2), col in transformedParams_new.iteritems():\n",
    "    colTups.append((l1,str(l2)))\n",
    "transformedParams_new.columns = pd.MultiIndex.from_tuples(colTups)\n",
    "#iGEM in python 3 .loc with missing column headers is giving issues. So changing it to reindex # can use transformedParams_train if running sequentially otherwise use transformedParamHeader after running above step\n",
    "predictedScores_new = pd.Series(reg.predict(scaler.transform(transformedParams_new.reindex(columns=transformedParams_train.columns).fillna(0).values)), index=transformedParams_new.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedScores_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedScores_new.to_csv(PREDICTED_SCORE_TABLE, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construct sgRNA libraries\n",
    "## Score sgRNAs for off-target potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are many ways to score sgRNAs as off-target; below is one listed one method that is simple and flexible,\n",
    "#but ignores gapped alignments, alternate PAMs, and uses bowtie which may not be maximally sensitive in all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iGEM the sequence length can be greather 22. So just added more pluses and adjusteed its length equal to sequence length.\n",
    "#iGEM Revisit to fix phred length properly.\n",
    "\n",
    "#output all sequences to a temporary FASTQ file for running bowtie alignment\n",
    "def outputTempBowtieFastq(libraryTable, outputFileName):\n",
    "    phredString = 'I4!=======44444++++++++++++++++' #weighting for how impactful mismatches are along sgRNA sequence \n",
    "    with open(outputFileName,'w') as outfile:\n",
    "        for name, row in libraryTable.iterrows():\n",
    "            outfile.write('@' + name + '\\n')\n",
    "            outfile.write('CCN' + str(Seq.Seq(row['sequence'][1:]).reverse_complement()) + '\\n')\n",
    "            outfile.write('+\\n')\n",
    "            outfile.write(phredString[0:3+len(str(Seq.Seq(row['sequence'][1:]).reverse_complement()))] + '\\n')\n",
    "            \n",
    "outputTempBowtieFastq(libraryTable_new, TEMP_FASTQ_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "fqFile = TEMP_FASTQ_FILE\n",
    "\n",
    "#specifying a list of parameters to run bowtie with\n",
    "#each tuple contains\n",
    "# *the mismatch threshold below which a site is considered a potential off-target (higher is more stringent)\n",
    "# *the number of sites allowed (1 is minimum since each sgRNA should have one true site in genome)\n",
    "# *the genome index against which to align the sgRNA sequences; these can be custom built to only consider sites near TSSs\n",
    "# *a name for the bowtie run to create appropriately named output files\n",
    "\n",
    "#iGEM\n",
    "#alignmentList = [(39,1,'~/indices/hg19.ensemblTSSflank500b','39_nearTSS'),\n",
    "#                (31,1,'~/indices/hg19.ensemblTSSflank500b','31_nearTSS'),\n",
    "#                (21,1,'~/indices/hg19.maskChrMandPAR','21_genome'),\n",
    "#                (31,2,'~/indices/hg19.ensemblTSSflank500b','31_2_nearTSS'),\n",
    "#                (31,3,'~/indices/hg19.ensemblTSSflank500b','31_3_nearTSS')]\n",
    "\n",
    "#iGEM   ChrM and PAR are vary small part of hg19. So running alignment for entire genome.\n",
    "\n",
    "alignmentList = [(39,1,LARGE_FILE_DIR+'large_data_files/indices/hg19.ensemblTSSflank500b','39_nearTSS'),\n",
    "                (31,1,LARGE_FILE_DIR+'large_data_files/indices/hg19.ensemblTSSflank500b','31_nearTSS'),\n",
    "                #(21,1,'/data/large_data_files/indices/hg19_maskChrMandPAR','21_genome'),\n",
    "                (21,1,LARGE_FILE_DIR+'large_data_files/indices/hg19','21_genome'),\n",
    "                (31,2,LARGE_FILE_DIR+'large_data_files/indices/hg19.ensemblTSSflank500b','31_2_nearTSS'),\n",
    "                (31,3,LARGE_FILE_DIR+'large_data_files/indices/hg19.ensemblTSSflank500b','31_3_nearTSS')]\n",
    "import os\n",
    "import errno\n",
    "if not os.path.exists('bowtie_output'):\n",
    "    os.makedirs('bowtie_output')\n",
    "\n",
    "alignmentColumns = []\n",
    "for btThreshold, mflag, bowtieIndex, runname in alignmentList:\n",
    "\n",
    "    alignedFile = 'bowtie_output/' + runname + '_aligned.txt'\n",
    "    unalignedFile = 'bowtie_output/' + runname + '_unaligned.fq'\n",
    "    maxFile = 'bowtie_output/' + runname + '_max.fq'\n",
    "    \n",
    "    bowtieString = 'bowtie -n 3 -l 15 -e '+str(btThreshold)+' -m ' + str(mflag) + ' --nomaqround -a --tryhard -p 16 --chunkmbs 256 ' + bowtieIndex + ' --suppress 5,6,7 --un ' + unalignedFile + ' --max ' + maxFile + ' '+ ' -q '+fqFile+' '+ alignedFile\n",
    "    print (bowtieString)\n",
    "    print (subprocess.call(bowtieString, shell=True))\n",
    "\n",
    "    #parse through the file of sgRNAs that exceeded \"m\", the maximum allowable alignments, and mark \"True\" any that are found\n",
    "    sgsAligning = set()\n",
    "    \n",
    "    try:\n",
    "        with open(maxFile) as infile:\n",
    "            sgsAligning = set()\n",
    "            for i, line in enumerate(infile):\n",
    "                if i%4 == 0: #id line\n",
    "                    sgsAligning.add(line.strip()[1:])\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.ENOENT:\n",
    "            raise\n",
    "\n",
    "    alignmentColumns.append(libraryTable_new.apply(lambda row: row.name in sgsAligning, axis=1))\n",
    "#iGEM zip is an object in python3    \n",
    "#collate results into a table, and flip the boolean values to yield the sgRNAs that passed filter as True\n",
    "alignmentTable = pd.concat(alignmentColumns,axis=1, keys=list(zip(*alignmentList))[3]).ne(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the top sgRNAs for a library, given predicted activity scores and off-target filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all generated data into one master table\n",
    "predictedScores_new.name = 'predicted score'\n",
    "v2Table = pd.concat((libraryTable_new, predictedScores_new, alignmentTable, sgInfoTable_new), axis=1, keys=['library table v2', 'predicted score', 'off-target filters', 'sgRNA info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#for our pCRISPRi/a-v2 vector, we append flanking sequences to each sgRNA sequence for cloning and require the oligo to contain\n",
    "#exactly 1 BstXI and BlpI site each for cloning, and exactly 0 SbfI sites for sequencing sample preparation\n",
    "restrictionSites = {re.compile('CCA......TGG'):1,\n",
    "                   re.compile('GCT.AGC'):1,\n",
    "                   re.compile('CCTGCAGG'):0}\n",
    "\n",
    "def matchREsites(sequence, REdict):\n",
    "    seq = sequence.upper()\n",
    "#iGEM in python 3 dict.iteritems is not present. So replace with dict.items        \n",
    "#    for resite, numMatchesExpected in restrictionSites.iteritems():\n",
    "    for resite, numMatchesExpected in restrictionSites.items():\n",
    "        if len(resite.findall(seq)) != numMatchesExpected:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def checkOverlaps(leftPosition, acceptedLeftPositions, nonoverlapMin):\n",
    "    for pos in acceptedLeftPositions:\n",
    "        if abs(pos - leftPosition) < nonoverlapMin:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flanking sequences\n",
    "upstreamConstant = 'CCACCTTGTTG'\n",
    "downstreamConstant = 'GTTTAAGAGCTAAGCTG'\n",
    "\n",
    "#minimum overlap between two sgRNAs targeting the same TSS\n",
    "nonoverlapMin = 3\n",
    "\n",
    "#number of sgRNAs to pick per gene/TSS\n",
    "sgRNAsToPick = 10\n",
    "\n",
    "#iGEM TODO need to enable 21_genome as well. temporarily disabled\n",
    "\n",
    "#list of off-target filter (or combinations of filters) levels, matching the names in the alignment table above\n",
    "offTargetLevels = [['31_nearTSS', '21_genome'],\n",
    "                  ['31_nearTSS'],\n",
    "                  ['21_genome'],\n",
    "                  ['31_2_nearTSS'],\n",
    "                  ['31_3_nearTSS']]\n",
    "\n",
    "#offTargetLevels = [ ['31_nearTSS'],\n",
    "#                  ['31_2_nearTSS'],\n",
    "#                  ['31_3_nearTSS']]\n",
    "\n",
    "\n",
    "#for each gene/TSS, go through each sgRNA in descending order of predicted score\n",
    "#if an sgRNA passes the restriction site, overlap, and off-target filters, accept it into the library\n",
    "#if the number of sgRNAs accepted is less than sgRNAsToPick, reduce off-target stringency by one and continue\n",
    "v2Groups = v2Table.groupby([('library table v2','gene'),('library table v2','transcripts')])\n",
    "newSgIds = []\n",
    "unfinishedTss = []\n",
    "for (gene, transcript), group in v2Groups:\n",
    "    geneSgIds = []\n",
    "    geneLeftPositions = []\n",
    "    empiricalSgIds = dict()\n",
    "    \n",
    "    stringency = 0\n",
    "#iGEM use sort_values instead of sort    \n",
    "    while len(geneSgIds) < sgRNAsToPick and stringency < len(offTargetLevels):\n",
    "        for sgId_v2, row in group.sort_values(('predicted score','predicted score'), ascending=False).iterrows():\n",
    "            oligoSeq = upstreamConstant + row[('library table v2','sequence')] + downstreamConstant\n",
    "            leftPos = row[('sgRNA info', 'position')] - (23 if row[('sgRNA info', 'strand')] == '-' else 0)\n",
    "            if len(geneSgIds) < sgRNAsToPick and row['off-target filters'].loc[offTargetLevels[stringency]].all() \\\n",
    "                and matchREsites(oligoSeq, restrictionSites) \\\n",
    "                and checkOverlaps(leftPos, geneLeftPositions, nonoverlapMin):\n",
    "                geneSgIds.append((sgId_v2,\n",
    "                                  gene,transcript,\n",
    "                                  row[('library table v2','sequence')], oligoSeq,\n",
    "                                  row[('predicted score','predicted score')], np.nan,\n",
    "                                 stringency))\n",
    "                geneLeftPositions.append(leftPos)\n",
    "                \n",
    "        stringency += 1\n",
    "            \n",
    "    if len(geneSgIds) < sgRNAsToPick:\n",
    "        unfinishedTss.append((gene, transcript)) #if the number of accepted sgRNAs is still less than sgRNAsToPick, discard gene\n",
    "    else:\n",
    "        newSgIds.extend(geneSgIds)\n",
    "        \n",
    "libraryTable_complete = pd.DataFrame(newSgIds, columns = ['sgID', 'gene', 'transcript','protospacer sequence', 'oligo sequence',\n",
    " 'predicted score', 'empirical score', 'off-target stringency']).set_index('sgID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfinishedTss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of sgRNAs accepted at each stringency level\n",
    "#iGEM newLibraryTable is not defined\n",
    "#newLibraryTable.groupby('off-target stringency').agg(len).iloc[:,0]\n",
    "libraryTable_complete.groupby('off-target stringency').agg(len).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of TSSs with fewer than required number of sgRNAs (and thus not included in the library)\n",
    "print (len(unfinishedTss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryTable_complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
